{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the Graph-Based Spatial Cross-Validation experiments from ICMLA21 Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Initialize libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\anaconda3\\envs\\graph_based_scv\\lib\\site-packages\\spaghetti\\network.py:36: FutureWarning: The next major release of pysal/spaghetti (2.0.0) will drop support for all ``libpysal.cg`` geometries. This change is a first step in refactoring ``spaghetti`` that is expected to result in dramatically reduced runtimes for network instantiation and operations. Users currently requiring network and point pattern input as ``libpysal.cg`` geometries should prepare for this simply by converting to ``shapely`` geometries.\n",
      "  warnings.warn(f\"{dep_msg}\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from weka.core import jvm\n",
    "from src import utils\n",
    "from src.pipeline import Pipeline\n",
    "from src.visualization.performance import VizMetrics\n",
    "from src.visualization.dependence import VizDependence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Initialize loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.initialize_coloredlog()\n",
    "utils.initialize_rich_tracerback()\n",
    "utils.initialize_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Initialize working path and enviromental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project path\n",
    "project_dir = os.path.abspath('')[:-5]\n",
    "# Load enviromental variables\n",
    "env_var = utils.load_env_variables(project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Set pipeline switchers, the default is to set True to all processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pipeline switchers\n",
    "SWITCHERS = {\n",
    "    \"scv\": False,\n",
    "    \"fs\": False,\n",
    "    \"train\": True,\n",
    "    \"predict\": True,\n",
    "    \"evaluate\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - List all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "brazil_removed_datasets = [\"Brazil_Election_2018_Sampled_dec0.3_prob0.1_removed_north\",\n",
    "                   \"Brazil_Election_2018_Sampled_dec0.3_prob0.1_removed_northeast\",\n",
    "                   \"Brazil_Election_2018_Sampled_dec0.3_prob0.1_removed_south\",\n",
    "                   \"Brazil_Election_2018_Sampled_dec0.3_prob0.1_removed_southeast\",\n",
    "                   \"Brazil_Election_2018_Sampled_dec0.3_prob0.1_removed_centerwest\"]\n",
    "\n",
    "brazil_datasets = [#\"Brazil_Election_2018_Sampled_dec0.3_prob0.1\",\n",
    "                  \"Brazil_Election_2018_Sampled_dec0.3_prob0.2\",\n",
    "                  #\"Brazil_Election_2018_Sampled_dec0.3_prob0.3\",\n",
    "                  \"Brazil_Election_2018_Sampled_dec0.3_prob0.4\",\n",
    "                  #\"Brazil_Election_2018_Sampled_dec0.3_prob0.5\",\n",
    "                  \"Brazil_Election_2018_Sampled_dec0.3_prob0.6\",\n",
    "                  #\"Brazil_Election_2018_Sampled_dec0.3_prob0.7\",\n",
    "                  \"Brazil_Election_2018_Sampled_dec0.3_prob0.8\",\n",
    "                  #\"Brazil_Election_2018_Sampled_dec0.3_prob0.9\"]\n",
    "                    ]\n",
    "\n",
    "brazil_geoeconomical_regions = [\"Brazil_Election_2018_removed_AMAZONIA\",\n",
    "                                \"Brazil_Election_2018_removed_NORDESTE\",\n",
    "                                \"Brazil_Election_2018_removed_CENTRO_SUL\"]\n",
    "\n",
    "us_datasets = [\"US_Corn_Yield_2016\", \"US_Wheat_Yield_2014\"]\n",
    "just_for_test = [\"Brazil_Election_2018_removed_CENTRO_SUL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Runs the pipeline for each method\n",
    "OBS: The results and files generated from the pipeline execution will be in the created folder Results in the data directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Traditional SCV\n",
    "OBS: We the the paramenter fast True so the semivariogram calculation step that can take 24h is skipped. We calculate the removing buffer by considering the 27 n-degree neighborhood as stated in the paper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the Traditional SCV approach for dataset: Brazil_Election_2018_Sampled_dec0.3_prob0.2 N = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model: 100%|██████████| 27/27 [00:01<00:00, 15.85it/s]\n",
      "Predicting test set: 100%|██████████| 27/27 [00:00<00:00, 44.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the Traditional SCV approach for dataset: Brazil_Election_2018_Sampled_dec0.3_prob0.4 N = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model: 100%|██████████| 27/27 [00:01<00:00, 21.59it/s]\n",
      "Predicting test set: 100%|██████████| 27/27 [00:00<00:00, 41.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the Traditional SCV approach for dataset: Brazil_Election_2018_Sampled_dec0.3_prob0.6 N = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model: 100%|██████████| 27/27 [00:02<00:00, 13.45it/s]\n",
      "Predicting test set: 100%|██████████| 27/27 [00:00<00:00, 59.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the Traditional SCV approach for dataset: Brazil_Election_2018_Sampled_dec0.3_prob0.8 N = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model: 100%|██████████| 27/27 [00:07<00:00,  3.39it/s]\n",
      "Predicting test set: 100%|██████████| 27/27 [00:00<00:00, 70.10it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_list = brazil_datasets\n",
    "fs_method = \"CFS\"\n",
    "ml_methods = [\"KNN_1\", \"OLS_1\", \"Lasso_1\", \"Ridge_1\", \"ElasticNet_1\", \"DT_1\", \"LGBM_1\", \"RF_1\", \"MLP_1\", \"SVM_1\"]\n",
    "\n",
    "\n",
    "if fs_method == \"CFS\" and SWITCHERS[\"fs\"]:\n",
    "    jvm.start()\n",
    "# Set paths\n",
    "meshblocks_filename = \"meshblocks.shp\"\n",
    "meshblocks_idx = \"code_muni\"\n",
    "data_idx = \"INDEX\"\n",
    "\n",
    "for dataset in dataset_list:\n",
    "    data_path = os.path.join(env_var[\"root_path\"], dataset, \"data.csv\")\n",
    "    meshblocks_path = os.path.join(env_var[\"root_path\"], dataset, \"meshblocks\", meshblocks_filename)\n",
    "    # Load data\n",
    "    data = pd.read_csv(data_path, index_col=data_idx, low_memory=False)\n",
    "    try:\n",
    "        data.drop(columns=[\"[GEO]_LATITUDE\", \"[GEO]_LONGITUDE\"], inplace=True)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    meshblocks = gpd.read_file(meshblocks_path)\n",
    "    # Set meshblocks  index\n",
    "    meshblocks.set_index(meshblocks_idx, inplace=True)\n",
    "    for ml_method in ml_methods:\n",
    "        # Run pipeline\n",
    "        TraditionalSCV = Pipeline(\n",
    "            root_path=os.path.join(env_var[\"root_path\"], dataset),\n",
    "            data=data,\n",
    "            meshblocks=meshblocks,\n",
    "            index_col=\"INDEX\",\n",
    "            fold_col=\"INDEX_FOLDS\",\n",
    "            target_col=\"TARGET\",\n",
    "            scv_method=\"TraditionalSCV\",\n",
    "            fs_method=fs_method,\n",
    "            ml_method=ml_method,\n",
    "            switchers=SWITCHERS\n",
    "        )\n",
    "\n",
    "        print(f\"Running the Traditional SCV approach for dataset: {dataset} ML Method = {ml_method}\")\n",
    "        TraditionalSCV.run()\n",
    "if fs_method == \"CFS\" and SWITCHERS[\"fs\"]:\n",
    "    jvm.stop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16e306bc925144e33eb7798286ee39e98b4eae36f3b0781ec31a8ce823bfdc1b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('graph_based_scv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
