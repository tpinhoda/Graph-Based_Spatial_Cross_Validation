{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the Graph-Based Spatial Cross-Validation experiments from ICMLA21 Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Initialize libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from weka.core import jvm\n",
    "from pathlib import Path\n",
    "from src import utils\n",
    "from src.pipeline import Pipeline\n",
    "from src.visualization.performance import VizMetrics\n",
    "from src.visualization.dependence import VizDependence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Initialize loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.initialize_coloredlog()\n",
    "utils.initialize_rich_tracerback()\n",
    "utils.initialize_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Initialize working path and enviromental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project path\n",
    "project_dir = str(Path().resolve().parents[1])\n",
    "# Load enviromental variables\n",
    "env_var = utils.load_env_variables(project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Set pipeline switchers, the default is to set True to all processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pipeline switchers\n",
    "SWITCHERS = {\n",
    "    \"scv\": False,\n",
    "    \"fs\": True,\n",
    "    \"train\": False,\n",
    "    \"predict\": False,\n",
    "    \"evaluate\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - List all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "brazil_removed_datasets = [\"Brazil_Election_2018_Sampled_dec0.3_prob0.1_removed_north\",\n",
    "                   \"Brazil_Election_2018_Sampled_dec0.3_prob0.1_removed_northeast\",\n",
    "                   \"Brazil_Election_2018_Sampled_dec0.3_prob0.1_removed_south\",\n",
    "                   \"Brazil_Election_2018_Sampled_dec0.3_prob0.1_removed_southeast\",\n",
    "                   \"Brazil_Election_2018_Sampled_dec0.3_prob0.1_removed_centerwest\"]\n",
    "\n",
    "brazil_datasets = [\"Brazil_Election_2018_Sampled_dec0.3_prob0.1\",\n",
    "                   \"Brazil_Election_2018_Sampled_dec0.3_prob0.2\",\n",
    "                   \"Brazil_Election_2018_Sampled_dec0.3_prob0.3\",\n",
    "                   \"Brazil_Election_2018_Sampled_dec0.3_prob0.4\",\n",
    "                   \"Brazil_Election_2018_Sampled_dec0.3_prob0.5\",\n",
    "                   \"Brazil_Election_2018_Sampled_dec0.3_prob0.6\",\n",
    "                   \"Brazil_Election_2018_Sampled_dec0.3_prob0.7\",\n",
    "                   \"Brazil_Election_2018_Sampled_dec0.3_prob0.8\",\n",
    "                   \"Brazil_Election_2018_Sampled_dec0.3_prob0.9\"]\n",
    "    \n",
    "\n",
    "brazil_geoeconomical_regions = [\"Brazil_Election_2018_removed_AMAZONIA\",\n",
    "                                \"Brazil_Election_2018_removed_NORDESTE\",\n",
    "                                \"Brazil_Election_2018_removed_CENTRO_SUL\"]\n",
    "\n",
    "us_corn_datasets = [\"US_Corn_Yield_2016_Removed_Northeast\",\n",
    "                    \"US_Corn_Yield_2016_Removed_Southeast\",\n",
    "                    \"US_Corn_Yield_2016_Removed_Midwest\",\n",
    "                    \"US_Corn_Yield_2016_Removed_Southwest\",\n",
    "                    \"US_Corn_Yield_2016_Removed_West\"]\n",
    "just_for_test = [\"Brazil_Election_2018\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Runs the pipeline for each method\n",
    "OBS: The results and files generated from the pipeline execution will be in the created folder Results in the data directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Traditional SCV\n",
    "OBS: We the the paramenter fast True so the semivariogram calculation step that can take 24h is skipped. We calculate the removing buffer by considering the 27 n-degree neighborhood as stated in the paper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the Traditional SCV approach for dataset: US_Corn_Yield_2016_Removed_Northeast ML Method = KNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|██████████| 31/31 [00:00<00:00, 200.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the Traditional SCV approach for dataset: US_Corn_Yield_2016_Removed_Southeast ML Method = KNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|██████████| 25/25 [00:00<00:00, 180.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the Traditional SCV approach for dataset: US_Corn_Yield_2016_Removed_Midwest ML Method = KNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|██████████| 24/24 [00:00<00:00, 180.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the Traditional SCV approach for dataset: US_Corn_Yield_2016_Removed_Southwest ML Method = KNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|██████████| 33/33 [00:00<00:00, 182.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the Traditional SCV approach for dataset: US_Corn_Yield_2016_Removed_West ML Method = KNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting Features: 100%|██████████| 31/31 [00:00<00:00, 190.44it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_list = us_corn_datasets\n",
    "fs_method = \"All\"\n",
    "#ml_methods = [\"KNN\", \"OLS\", \"Lasso\", \"Ridge\", \"ElasticNet\", \"DT\", \"LGBM\", \"RF\", \"MLP\", \"SVM\"]\n",
    "ml_methods = [\"KNN\"]\n",
    "\n",
    "if fs_method == \"CFS\" and SWITCHERS[\"fs\"]:\n",
    "    jvm.start()\n",
    "# Set paths\n",
    "meshblocks_filename = \"cb_2016_us_county_500k.shp\"\n",
    "meshblocks_idx = \"GEOID\"\n",
    "data_idx = \"INDEX\"\n",
    "env_var[\"root_path\"] = \"/exp/tpinho/Datasets/US_Corn_Yield_2016\"\n",
    "for dataset in dataset_list:\n",
    "    data_path = os.path.join(env_var[\"root_path\"], dataset, \"data.csv\")\n",
    "    meshblocks_path = os.path.join(env_var[\"root_path\"], dataset, \"meshblocks\", meshblocks_filename)\n",
    "    # Load data\n",
    "    data = pd.read_csv(data_path, index_col=data_idx, low_memory=False)\n",
    "    try:\n",
    "        data.drop(columns=[\"[GEO]_LATITUDE\", \"[GEO]_LONGITUDE\"], inplace=True)\n",
    "    except KeyError:\n",
    "        pass\n",
    "    meshblocks = gpd.read_file(meshblocks_path)\n",
    "    # Set meshblocks  index\n",
    "    meshblocks.set_index(meshblocks_idx, inplace=True)\n",
    "    for ml_method in ml_methods:\n",
    "        # Run pipeline\n",
    "        TraditionalSCV = Pipeline(\n",
    "            root_path=os.path.join(env_var[\"root_path\"], dataset),\n",
    "            data=data,\n",
    "            meshblocks=meshblocks,\n",
    "            index_col=\"INDEX\",\n",
    "            fold_col=\"INDEX_FOLDS\",\n",
    "            target_col=\"TARGET\",\n",
    "            scv_method=\"TraditionalSCV\",\n",
    "            fs_method=fs_method,\n",
    "            ml_method=ml_method,\n",
    "            switchers=SWITCHERS\n",
    "        )\n",
    "\n",
    "        print(f\"Running the Traditional SCV approach for dataset: {dataset} ML Method = {ml_method}\")\n",
    "        TraditionalSCV.run()\n",
    "if fs_method == \"CFS\" and SWITCHERS[\"fs\"]:\n",
    "    jvm.stop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16e306bc925144e33eb7798286ee39e98b4eae36f3b0781ec31a8ce823bfdc1b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
