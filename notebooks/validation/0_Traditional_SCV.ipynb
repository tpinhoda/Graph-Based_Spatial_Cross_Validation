{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the Graph-Based Spatial Cross-Validation experiments from ICMLA21 Paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Initialize libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from weka.core import jvm\n",
    "from pathlib import Path\n",
    "from src import utils\n",
    "from src.pipeline import Pipeline\n",
    "from src.visualization.performance import VizMetrics\n",
    "from src.visualization.dependence import VizDependence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Initialize loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.initialize_coloredlog()\n",
    "utils.initialize_rich_tracerback()\n",
    "utils.initialize_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Initialize working path and enviromental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project path\n",
    "project_dir = str(Path().resolve().parents[1])\n",
    "# Load enviromental variables\n",
    "env_var = utils.load_env_variables(project_dir)\n",
    "# Load parameters\n",
    "dataset = \"Brazil_Election_2018\"\n",
    "parameters = utils.load_json(os.path.join(project_dir, \"parameters\", \"validation\", f\"{dataset}.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Set pipeline switchers, the default is to set True to all processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pipeline switchers\n",
    "SWITCHERS = {\n",
    "    \"scv\": True,\n",
    "    \"fs\": True,\n",
    "    \"train\": True,\n",
    "    \"predict\": False,\n",
    "    \"evaluate\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - List all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = os.path.join(env_var[\"root_path\"], dataset)\n",
    "dataset_list = [folder for folder in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, folder))]\n",
    "dataset_list.remove(\"Original\")\n",
    "dataset_list.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Runs the pipeline for each method\n",
    "OBS: The results and files generated from the pipeline execution will be in the created folder Results in the data directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Traditional SCV\n",
    "OBS: We the the paramenter fast True so the semivariogram calculation step that can take 24h is skipped. We calculate the removing buffer by considering the 27 n-degree neighborhood as stated in the paper "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 14:31:09 labics01 weka.core.jvm[6102] INFO JVM already running, call jvm.stop() first\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭──────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_6102/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">578792420.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">29</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 10&gt;</span>                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] Arquivo ou diretório não encontrado: '/tmp/ipykernel_6102/578792420.py'</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰───────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'targer_cols'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m─────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_6102/\u001b[0m\u001b[1;33m578792420.py\u001b[0m:\u001b[94m29\u001b[0m in \u001b[92m<cell line: 10>\u001b[0m                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] Arquivo ou diretório não encontrado: '/tmp/ipykernel_6102/578792420.py'\u001b[0m         \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰───────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'targer_cols'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fs_method = parameters[\"fs_method\"]\n",
    "ml_methods = parameters[\"ml_methods\"]\n",
    "# Set paths\n",
    "meshblocks_filename = parameters[\"meshblock\"]\n",
    "meshblocks_idx = parameters[\"meshblock_id\"]\n",
    "dataset_path = os.path.join(env_var[\"root_path\"], dataset)\n",
    "\n",
    "if fs_method == \"CFS\" and SWITCHERS[\"fs\"]:\n",
    "    jvm.start()\n",
    "for dataset in dataset_list:\n",
    "    data_path = os.path.join(dataset_path, dataset, \"data.csv\")\n",
    "    meshblocks_path = os.path.join(dataset_path, dataset, \"meshblocks\", meshblocks_filename)\n",
    "    # Load data\n",
    "    data = pd.read_csv(data_path, index_col=parameters[\"index_col\"], low_memory=False)\n",
    "    meshblocks = gpd.read_file(meshblocks_path)\n",
    "    # Remove uncessary cols\n",
    "    if parameters[\"cols_remove\"]:\n",
    "        data.drop(columns=parameters[\"cols_remove\"], inplace=True)\n",
    "    # Set meshblocks  index\n",
    "    meshblocks.set_index(meshblocks_idx, inplace=True)\n",
    "    for ml_method in ml_methods:\n",
    "        # Run pipeline\n",
    "        TraditionalSCV = Pipeline(\n",
    "            root_path=os.path.join(dataset_path, dataset),\n",
    "            data=data,\n",
    "            meshblocks=meshblocks,\n",
    "            index_col=parameters[\"index_col\"],\n",
    "            fold_col=parameters[\"fold_col\"],\n",
    "            target_col=parameters[\"target_col\"],\n",
    "            scv_method=\"TraditionalSCV\",\n",
    "            fs_method=fs_method,\n",
    "            ml_method=ml_method,\n",
    "            switchers=SWITCHERS\n",
    "        )\n",
    "\n",
    "        print(f\"Running the Traditional SCV approach for dataset: {dataset} ML Method = {ml_method}\")\n",
    "        TraditionalSCV.run()\n",
    "if fs_method == \"CFS\" and SWITCHERS[\"fs\"]:\n",
    "    jvm.stop()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "16e306bc925144e33eb7798286ee39e98b4eae36f3b0781ec31a8ce823bfdc1b"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
